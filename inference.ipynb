{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combined Triplet Extractor initialized!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from document_pipeline import DocumentPipeline\n",
    "\n",
    "\n",
    "config = json.load(open(\"config.json\"))\n",
    "pipeline = DocumentPipeline(config[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Document was split into 12 documents\n",
      "Total number of triplets: 61\n"
     ]
    }
   ],
   "source": [
    "triplets = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphs.knowledge_graph.knowledge_graph import Neo4JGraph\n",
    "\n",
    "\n",
    "neo4j_graph = Neo4JGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [00:20<00:00,  3.04it/s]\n"
     ]
    }
   ],
   "source": [
    "neo4j_graph.populate(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphs.graph import Graph\n",
    "\n",
    "\n",
    "graph = Graph(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NodeDataView({'PERSON ZIYU WANG': {'type': 'PERSON', 'name': 'ZIYU WANG', 'descriptions': ['Ziyu Wang is a researcher associated with Google DeepMind, contributing to advancements in deep reinforcement learning.']}, 'ORGANIZATION GOOGLE DEEPMIND': {'type': 'ORGANIZATION', 'name': 'GOOGLE DEEPMIND', 'descriptions': ['Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.', 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.', 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.', 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.', 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.', 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.', 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.']}, 'PERSON TOM SCHAUL': {'type': 'PERSON', 'name': 'TOM SCHAUL', 'descriptions': ['Tom Schaul is a researcher at Google DeepMind, known for his work in reinforcement learning and neural network architectures.']}, 'PERSON MATTEO HESSEL': {'type': 'PERSON', 'name': 'MATTEO HESSEL', 'descriptions': ['Matteo Hessel is a researcher at Google DeepMind, focusing on deep learning and reinforcement learning methodologies.']}, 'PERSON HADO VAN HASSELT': {'type': 'PERSON', 'name': 'HADO VAN HASSELT', 'descriptions': ['Hado van Hasselt is a researcher at Google DeepMind, contributing to the development of algorithms in reinforcement learning.']}, 'PERSON MARC LANCTOT': {'type': 'PERSON', 'name': 'MARC LANCTOT', 'descriptions': ['Marc Lanctot is a researcher at Google DeepMind, involved in the study of game theory and reinforcement learning.']}, 'PERSON NANDO DE FREITAS': {'type': 'PERSON', 'name': 'NANDO DE FREITAS', 'descriptions': ['Nando de Freitas is a prominent researcher at Google DeepMind, specializing in machine learning and artificial intelligence.']}, 'ARCHITECTURE DUELING NETWORK ARCHITECTURE': {'type': 'ARCHITECTURE', 'name': 'DUELING NETWORK ARCHITECTURE', 'descriptions': ['The Dueling Network Architecture is a neural network design that separates the representation of state values and action advantages for improved reinforcement learning.', 'The Dueling Network Architecture is a neural network design that separates the representation of state values and action advantages for improved reinforcement learning.', 'The dueling network architecture is a design for Q-networks that separates the estimation of state values and action advantages to improve learning efficiency.']}, 'GAME ATARI 2600': {'type': 'GAME', 'name': 'ATARI 2600', 'descriptions': ['Atari 2600 is a classic video game console used as a benchmark for testing reinforcement learning algorithms.', 'Atari 2600 is a classic video game console that serves as a testbed for reinforcement learning algorithms, where agents learn to play various games.', 'Atari 2600 is a classic video game console that serves as a testbed for reinforcement learning algorithms, where agents learn to play various games.']}, 'ARCHITECTURE DUELING NETWORK': {'type': 'ARCHITECTURE', 'name': 'DUELING NETWORK', 'descriptions': ['The dueling network is a deep learning architecture that separates the estimation of state value and advantage functions, improving learning efficiency in reinforcement learning tasks.', 'The dueling network is a deep learning architecture that separates the estimation of state value and advantage functions, improving learning efficiency in reinforcement learning tasks.', 'The dueling network is a deep learning architecture that separates the estimation of state value and advantage functions, improving learning efficiency in reinforcement learning tasks.', 'The Dueling Network architecture is a deep reinforcement learning model that separates the estimation of the value and advantage functions through two streams of fully connected layers.', 'The Dueling Network architecture is a deep reinforcement learning model that separates the estimation of the value and advantage functions through two streams of fully connected layers.', 'The Dueling Network architecture is a deep reinforcement learning model that separates the estimation of the value and advantage functions through two streams of fully connected layers.']}, 'ALGORITHM DEEP Q-NETWORKS': {'type': 'ALGORITHM', 'name': 'DEEP Q-NETWORKS', 'descriptions': ['Deep Q-Networks (DQN) is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.', 'Deep Q-Networks (DQN) is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.']}, 'TECHNOLOGY SALIENT MAPS': {'type': 'TECHNOLOGY', 'name': 'SALIENT MAPS', 'descriptions': ['Saliency maps are visual representations that highlight important features in input data, used to understand the focus of neural networks during decision-making.', 'Saliency maps are visual representations that highlight important features in input data, used to understand the focus of neural networks during decision-making.']}, 'METHODOLOGY JACOBIANS': {'type': 'METHODOLOGY', 'name': 'JACOBIANS', 'descriptions': ['Jacobian matrices are used in the computation of gradients, which help in understanding how changes in input affect the output of a neural network.']}, 'TECHNOLOGY DEEP Q-NETWORK': {'type': 'TECHNOLOGY', 'name': 'DEEP Q-NETWORK', 'descriptions': ['A deep Q-network is a neural network used to approximate the Q-function in reinforcement learning, allowing for the estimation of state-action values.']}, 'METHODOLOGY REINFORCEMENT LEARNING': {'type': 'METHODOLOGY', 'name': 'REINFORCEMENT LEARNING', 'descriptions': ['Reinforcement learning is a type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize cumulative reward.']}, 'ALGORITHM ADVANTAGE FUNCTION': {'type': 'ALGORITHM', 'name': 'ADVANTAGE FUNCTION', 'descriptions': ['The advantage function measures the relative value of taking a specific action in a given state compared to the average value of all actions in that state.', 'The advantage function measures the relative value of taking a specific action in a given state compared to the average value of all actions in that state.']}, 'ALGORITHM STATE-ACTION VALUE FUNCTION': {'type': 'ALGORITHM', 'name': 'STATE-ACTION VALUE FUNCTION', 'descriptions': ['The state-action value function, or Q-function, estimates the expected return of taking a specific action in a given state under a particular policy.', 'The state-action value function, or Q-function, estimates the expected return of taking a specific action in a given state under a particular policy.']}, 'ALGORITHM BELLMAN EQUATION': {'type': 'ALGORITHM', 'name': 'BELLMAN EQUATION', 'descriptions': ['The Bellman equation is a fundamental recursive equation in dynamic programming and reinforcement learning that relates the value of a state to the values of its successor states.']}, 'METHODOLOGY POLICY GRADIENTS': {'type': 'METHODOLOGY', 'name': 'POLICY GRADIENTS', 'descriptions': ['Policy gradients are a class of algorithms in reinforcement learning that optimize the policy directly by adjusting the parameters in the direction of the gradient of expected reward.']}, 'TECHNOLOGY DQN': {'type': 'TECHNOLOGY', 'name': 'DQN', 'descriptions': ['DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.', 'DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.', 'DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.', 'DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.', 'DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.']}, 'TECHNOLOGY DDQN': {'type': 'TECHNOLOGY', 'name': 'DDQN', 'descriptions': ['DDQN, or Double Deep Q-Network, is an improved version of DQN that mitigates overestimation bias by using two separate networks for action selection and evaluation.', 'DDQN, or Double Deep Q-Network, is an improved version of DQN that mitigates overestimation bias by using two separate networks for action selection and evaluation.', 'DDQN, or Double Deep Q-Network, is an improved version of DQN that mitigates overestimation bias by using two separate networks for action selection and evaluation.']}, 'METHODOLOGY EXPERIENCE REPLAY': {'type': 'METHODOLOGY', 'name': 'EXPERIENCE REPLAY', 'descriptions': ['Experience replay is a technique used in reinforcement learning where past experiences are stored and reused to improve learning efficiency and reduce variance.', 'Experience replay is a technique used in reinforcement learning where past experiences are stored and reused to improve learning efficiency and reduce variance.', 'Experience replay is a technique used in reinforcement learning where past experiences are stored and reused to improve learning efficiency and reduce variance.']}, 'METHODOLOGY PRIORITIZED REPLAY': {'type': 'METHODOLOGY', 'name': 'PRIORITIZED REPLAY', 'descriptions': ['Prioritized replay is an enhancement of experience replay that increases the probability of sampling experiences that are expected to provide more learning progress.', 'Prioritized replay is an enhancement of experience replay that increases the probability of sampling experiences that are expected to provide more learning progress.']}, 'PERSON MNIH ET AL.': {'type': 'PERSON', 'name': 'MNIH ET AL.', 'descriptions': ['Mnih et al. refers to a group of researchers who developed the original DQN algorithm and contributed significantly to the field of deep reinforcement learning.']}, 'PERSON VAN HASSELT ET AL.': {'type': 'PERSON', 'name': 'VAN HASSELT ET AL.', 'descriptions': ['Van Hasselt et al. refers to researchers who proposed the Double DQN algorithm to address issues with the original DQN.']}, 'PERSON SCHAUL ET AL.': {'type': 'PERSON', 'name': 'SCHAUL ET AL.', 'descriptions': ['Schaul et al. refers to researchers who introduced prioritized experience replay, enhancing the efficiency of reinforcement learning.']}, 'DOMAIN ATARI BENCHMARK SUITE': {'type': 'DOMAIN', 'name': 'ATARI BENCHMARK SUITE', 'descriptions': ['The Atari benchmark suite is a collection of video games used to evaluate the performance of reinforcement learning algorithms.']}, 'TECHNOLOGY Q-FUNCTION': {'type': 'TECHNOLOGY', 'name': 'Q-FUNCTION', 'descriptions': ['The Q-function is a function used in reinforcement learning that estimates the expected utility of taking a given action in a given state.', 'The Q-function is a function used in reinforcement learning that estimates the expected utility of taking a given action in a given state.', 'The Q-function is a function used in reinforcement learning that estimates the expected utility of taking a given action in a given state.']}, 'ALGORITHM DDQN': {'type': 'ALGORITHM', 'name': 'DDQN', 'descriptions': ['DDQN, or Double Deep Q-Network, is an algorithm that addresses the overestimation bias of Q-learning by using two separate networks to estimate the Q-values.', 'DDQN, or Double Deep Q-Network, is an algorithm that addresses the overestimation bias of Q-learning by using two separate networks to estimate the Q-values.', 'DDQN (Double Deep Q-Network) is an algorithm that addresses the overestimation bias of Q-learning by using two separate networks to estimate action values.', 'DDQN (Double Deep Q-Network) is an algorithm that addresses the overestimation bias of Q-learning by using two separate networks to estimate action values.', 'DDQN (Double Deep Q-Network) is an algorithm that addresses the overestimation bias of Q-learning by using two separate networks to estimate action values.']}, 'ALGORITHM SARSA': {'type': 'ALGORITHM', 'name': 'SARSA', 'descriptions': ['SARSA (State-Action-Reward-State-Action) is an on-policy reinforcement learning algorithm that updates the Q-values based on the action taken by the agent.', 'SARSA (State-Action-Reward-State-Action) is an on-policy reinforcement learning algorithm that updates the Q-values based on the action taken by the agent.']}, 'TECHNOLOGY EQUATION (9)': {'type': 'TECHNOLOGY', 'name': 'EQUATION (9)', 'descriptions': ['Equation (9) is a mathematical formulation used in the experiments to help with identifiability and to evaluate Q-values in reinforcement learning.']}, 'ARCHITECTURE DUELING ARCHITECTURE': {'type': 'ARCHITECTURE', 'name': 'DUELING ARCHITECTURE', 'descriptions': ['The dueling architecture is a neural network design that separates the representation of state values and advantages to improve learning in reinforcement learning tasks.', 'The dueling architecture is a neural network design that separates the representation of state values and advantages to improve learning in reinforcement learning tasks.', 'The dueling architecture is a neural network design that separates the representation of state values and advantages to improve learning in reinforcement learning tasks.', 'The dueling architecture is a neural network design that separates the representation of state values and advantages to improve learning in reinforcement learning tasks.', 'Dueling architecture is a neural network design that separates the representation of state values and action advantages to improve learning efficiency in reinforcement learning.', 'Dueling architecture is a neural network architecture used in deep reinforcement learning that separates the representation of state values and advantages to improve learning efficiency.', 'Dueling architecture is a neural network architecture used in deep reinforcement learning that separates the representation of state values and advantages to improve learning efficiency.', 'Dueling architecture is a neural network design that separates the representation of state values and action advantages, improving the learning efficiency in reinforcement learning tasks.', 'Dueling architecture is a neural network design that separates the representation of state values and action advantages, improving the learning efficiency in reinforcement learning tasks.']}, 'ALGORITHM DEEP Q-NETWORK': {'type': 'ALGORITHM', 'name': 'DEEP Q-NETWORK', 'descriptions': ['The deep Q-network is a reinforcement learning algorithm that uses deep learning to approximate Q-values for decision making.']}, 'GAME ATARI GAME-PLAYING': {'type': 'GAME', 'name': 'ATARI GAME-PLAYING', 'descriptions': ['Atari game-playing refers to the use of reinforcement learning algorithms to learn and play various Atari video games.']}, 'ENVIRONMENT CORRIDOR ENVIRONMENT': {'type': 'ENVIRONMENT', 'name': 'CORRIDOR ENVIRONMENT', 'descriptions': ['The corridor environment is a simple setup used for evaluating reinforcement learning algorithms, consisting of connected corridors where an agent must navigate to achieve rewards.', 'The Corridor Environment is a simulated environment used in reinforcement learning experiments where an agent navigates through a corridor to reach reward states.']}, 'TECHNOLOGY DUELING NETWORK ARCHITECTURES': {'type': 'TECHNOLOGY', 'name': 'DUELING NETWORK ARCHITECTURES', 'descriptions': ['Dueling Network Architectures are a type of neural network architecture used in deep reinforcement learning that improves convergence speed by learning a general value shared across similar actions.', 'Dueling Network Architectures are a type of neural network architecture used in deep reinforcement learning that improves convergence speed by learning a general value shared across similar actions.']}, 'METHODOLOGY DEEP REINFORCEMENT LEARNING': {'type': 'METHODOLOGY', 'name': 'DEEP REINFORCEMENT LEARNING', 'descriptions': ['Deep Reinforcement Learning is a methodology that combines reinforcement learning with deep learning to enable agents to learn optimal behaviors in complex environments.', 'Deep Reinforcement Learning is a methodology that combines reinforcement learning with deep learning to enable agents to learn optimal behaviors in complex environments.', 'Deep reinforcement learning is a methodology that combines reinforcement learning with deep learning, enabling agents to learn optimal behaviors in complex environments through trial and error.', 'Deep reinforcement learning is a methodology that combines reinforcement learning with deep learning, enabling agents to learn optimal behaviors in complex environments through trial and error.', 'Deep reinforcement learning is a methodology that combines reinforcement learning with deep learning, enabling agents to learn optimal behaviors in complex environments through trial and error.']}, 'ALGORITHM DDQN ALGORITHM': {'type': 'ALGORITHM', 'name': 'DDQN ALGORITHM', 'descriptions': ['The DDQN (Double Deep Q-Network) algorithm is an enhancement of the Q-learning algorithm that reduces overestimation bias in action value estimates.']}, 'GAME ATARI GAMES': {'type': 'GAME', 'name': 'ATARI GAMES', 'descriptions': ['Atari Games are a collection of video games used as benchmarks in reinforcement learning research, known for their diverse gameplay and high-dimensional observations.', 'Atari Games are a collection of video games used as benchmarks in reinforcement learning research, known for their diverse gameplay and high-dimensional observations.']}, 'PERSON VAN HASSELT ET AL. (2015)': {'type': 'PERSON', 'name': 'VAN HASSELT ET AL. (2015)', 'descriptions': ['Van Hasselt et al. (2015) is a research team known for their contributions to deep reinforcement learning, particularly in the development of the DDQN algorithm.', 'Van Hasselt et al. (2015) is a research team known for their contributions to deep reinforcement learning, particularly in the development of the DDQN algorithm.']}, 'ALGORITHM NATURE DQN': {'type': 'ALGORITHM', 'name': 'NATURE DQN', 'descriptions': ['Nature DQN is a deep reinforcement learning algorithm introduced by Mnih et al. (2015) that combines deep learning with Q-learning to play Atari games.']}, 'ENVIRONMENT ALE': {'type': 'ENVIRONMENT', 'name': 'ALE', 'descriptions': ['ALE (Arcade Learning Environment) is a framework for developing and evaluating reinforcement learning agents in a variety of Atari games.']}, 'ALGORITHM DUEL CLIP': {'type': 'ALGORITHM', 'name': 'DUEL CLIP', 'descriptions': ['Duel Clip is an algorithm that performs better than Single Clip on 75.4% of the games and achieves human-level performance on 42 out of 57 Atari games.', 'Duel Clip is an algorithm that performs better than Single Clip on 75.4% of the games and achieves human-level performance on 42 out of 57 Atari games.', 'Duel Clip is an algorithm that performs better than Single Clip on 75.4% of the games and achieves human-level performance on 42 out of 57 Atari games.', 'Duel Clip is an algorithm that performs better than Single Clip on 75.4% of the games and achieves human-level performance on 42 out of 57 Atari games.']}, 'ALGORITHM SINGLE CLIP': {'type': 'ALGORITHM', 'name': 'SINGLE CLIP', 'descriptions': ['Single Clip is an algorithm that is outperformed by Duel Clip in various metrics across Atari games.', 'Single Clip is an algorithm that is outperformed by Duel Clip in various metrics across Atari games.']}, 'ALGORITHM SINGLE': {'type': 'ALGORITHM', 'name': 'SINGLE', 'descriptions': ['Single is a baseline algorithm that Duel Clip outperforms on 80.7% of the games.', 'Single is a baseline algorithm that Duel Clip outperforms on 80.7% of the games.']}, 'METHODOLOGY GRADIENT CLIPPING': {'type': 'METHODOLOGY', 'name': 'GRADIENT CLIPPING', 'descriptions': ['Gradient clipping is a technique incorporated in the new approaches to improve performance.', 'Gradient clipping is a technique incorporated in the new approaches to improve performance.', 'Gradient clipping is a technique used to prevent exploding gradients by capping the gradients during backpropagation to a specified threshold.']}, 'METHODOLOGY PRIORITIZED EXPERIENCE REPLAY': {'type': 'METHODOLOGY', 'name': 'PRIORITIZED EXPERIENCE REPLAY', 'descriptions': ['Prioritized Experience Replay is a methodology that improves the performance of Atari games by prioritizing experience tuples for learning.', 'Prioritized Experience Replay is a methodology that improves the performance of Atari games by prioritizing experience tuples for learning.']}, 'ALGORITHM PRIORITIZED DDQN': {'type': 'ALGORITHM', 'name': 'PRIORITIZED DDQN', 'descriptions': ['Prioritized DDQN is an algorithm that enhances the standard Double Deep Q-Network by prioritizing the experience replay based on the TD-error, allowing the agent to learn more effectively from important transitions.', 'Prioritized DDQN is an algorithm that enhances the standard Double Deep Q-Network by prioritizing the experience replay based on the TD-error, allowing the agent to learn more effectively from important transitions.', 'Prioritized DDQN is an algorithm that enhances the standard Double Deep Q-Network by prioritizing the experience replay based on the TD-error, allowing the agent to learn more effectively from important transitions.']}, 'DOMAIN ATARI GAMES': {'type': 'DOMAIN', 'name': 'ATARI GAMES', 'descriptions': ['Atari games are a set of classic video games used as benchmarks in reinforcement learning research, providing a diverse set of environments for training and evaluating agents.']}, 'GAME ENDURO': {'type': 'GAME', 'name': 'ENDURO', 'descriptions': ['Enduro is an Atari game where players control a car in a racing environment, focusing on endurance and performance over time.']}, 'TECHNOLOGY DEEP Q-NETWORKS': {'type': 'TECHNOLOGY', 'name': 'DEEP Q-NETWORKS', 'descriptions': ['Deep Q-Networks (DQN) are a type of deep learning model used in reinforcement learning that combines Q-learning with deep neural networks to approximate Q-values.', 'Deep Q-Networks (DQN) are a type of deep learning model used in reinforcement learning that combines Q-learning with deep neural networks to approximate Q-values.']}, 'METHODOLOGY Q-LEARNING': {'type': 'METHODOLOGY', 'name': 'Q-LEARNING', 'descriptions': ['Q-learning is a reinforcement learning algorithm that seeks to learn the value of an action in a particular state, allowing an agent to learn how to optimally act in an environment.']}, 'GAME SEAQUEST': {'type': 'GAME', 'name': 'SEAQUEST', 'descriptions': ['Seaquest is an Atari game used as a benchmark for testing reinforcement learning algorithms, where players control a submarine to rescue divers while avoiding enemy attacks.', 'Seaquest is an Atari game used as a benchmark for testing reinforcement learning algorithms, where players control a submarine to rescue divers while avoiding enemy attacks.']}, 'DOMAIN ATARI DOMAIN': {'type': 'DOMAIN', 'name': 'ATARI DOMAIN', 'descriptions': ['The Atari domain refers to a set of video games developed by Atari, which are commonly used as environments for testing reinforcement learning algorithms.']}, 'ORGANIZATION ICLR': {'type': 'ORGANIZATION', 'name': 'ICLR', 'descriptions': ['ICLR (International Conference on Learning Representations) is a prominent conference in the field of machine learning and artificial intelligence, focusing on deep learning and representation learning.']}, 'EVENT DEEP LEARNING WORKSHOP': {'type': 'EVENT', 'name': 'DEEP LEARNING WORKSHOP', 'descriptions': ['The Deep Learning Workshop is an event held at ICML that focuses on advancements and research in deep learning techniques and applications.']}, 'ORGANIZATION NATURE': {'type': 'ORGANIZATION', 'name': 'NATURE', 'descriptions': ['Nature is a leading international journal that publishes research across a wide range of scientific disciplines, including significant studies in artificial intelligence and machine learning.']}, 'ORGANIZATION ARXIV': {'type': 'ORGANIZATION', 'name': 'ARXIV', 'descriptions': ['arXiv is a repository of electronic preprints (known as e-prints) in various fields of science, including computer science, where researchers share their findings before formal peer review.']}, 'EVENT NIPS': {'type': 'EVENT', 'name': 'NIPS', 'descriptions': ['NIPS (NeurIPS) is the Conference on Neural Information Processing Systems, a premier conference in machine learning and computational neuroscience.']}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.graph.nodes[\"ORGANIZATION GOOGLE DEEPMIND\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EdgeDataView([('ORGANIZATION GOOGLE DEEPMIND', 'PERSON ZIYU WANG', {'descriptions': ['Ziyu Wang is a researcher at Google DeepMind, contributing to the development of reinforcement learning techniques.'], 'strengths': [9]}), ('ORGANIZATION GOOGLE DEEPMIND', 'PERSON TOM SCHAUL', {'descriptions': ['Tom Schaul is a researcher at Google DeepMind, focusing on advancements in deep reinforcement learning.'], 'strengths': [9]}), ('ORGANIZATION GOOGLE DEEPMIND', 'PERSON MATTEO HESSEL', {'descriptions': ['Matteo Hessel is a researcher at Google DeepMind, working on deep learning methodologies.'], 'strengths': [9]}), ('ORGANIZATION GOOGLE DEEPMIND', 'PERSON HADO VAN HASSELT', {'descriptions': ['Hado van Hasselt is a researcher at Google DeepMind, contributing to reinforcement learning algorithms.'], 'strengths': [9]}), ('ORGANIZATION GOOGLE DEEPMIND', 'PERSON MARC LANCTOT', {'descriptions': ['Marc Lanctot is a researcher at Google DeepMind, involved in reinforcement learning research.'], 'strengths': [9]}), ('ORGANIZATION GOOGLE DEEPMIND', 'PERSON NANDO DE FREITAS', {'descriptions': ['Nando de Freitas is a prominent researcher at Google DeepMind, specializing in machine learning.'], 'strengths': [9]}), ('ORGANIZATION GOOGLE DEEPMIND', 'ARCHITECTURE DUELING NETWORK ARCHITECTURE', {'descriptions': ['The Dueling Network Architecture was developed by researchers at Google DeepMind to enhance reinforcement learning.'], 'strengths': [8]})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.graph.edges(\"ORGANIZATION GOOGLE DEEPMIND\", data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject': {'name': 'ZIYU WANG', 'type': 'PERSON', 'description': 'Ziyu Wang is a researcher associated with Google DeepMind, contributing to advancements in deep reinforcement learning.'}, 'object': {'name': 'GOOGLE DEEPMIND', 'type': 'ORGANIZATION', 'description': 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.'}, 'relationship': {'description': 'Ziyu Wang is a researcher at Google DeepMind, contributing to the development of reinforcement learning techniques.', 'strength': 9}}\n",
      "{'subject': {'name': 'TOM SCHAUL', 'type': 'PERSON', 'description': 'Tom Schaul is a researcher at Google DeepMind, known for his work in reinforcement learning and neural network architectures.'}, 'object': {'name': 'GOOGLE DEEPMIND', 'type': 'ORGANIZATION', 'description': 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.'}, 'relationship': {'description': 'Tom Schaul is a researcher at Google DeepMind, focusing on advancements in deep reinforcement learning.', 'strength': 9}}\n",
      "{'subject': {'name': 'MATTEO HESSEL', 'type': 'PERSON', 'description': 'Matteo Hessel is a researcher at Google DeepMind, focusing on deep learning and reinforcement learning methodologies.'}, 'object': {'name': 'GOOGLE DEEPMIND', 'type': 'ORGANIZATION', 'description': 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.'}, 'relationship': {'description': 'Matteo Hessel is a researcher at Google DeepMind, working on deep learning methodologies.', 'strength': 9}}\n",
      "{'subject': {'name': 'HADO VAN HASSELT', 'type': 'PERSON', 'description': 'Hado van Hasselt is a researcher at Google DeepMind, contributing to the development of algorithms in reinforcement learning.'}, 'object': {'name': 'GOOGLE DEEPMIND', 'type': 'ORGANIZATION', 'description': 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.'}, 'relationship': {'description': 'Hado van Hasselt is a researcher at Google DeepMind, contributing to reinforcement learning algorithms.', 'strength': 9}}\n",
      "{'subject': {'name': 'MARC LANCTOT', 'type': 'PERSON', 'description': 'Marc Lanctot is a researcher at Google DeepMind, involved in the study of game theory and reinforcement learning.'}, 'object': {'name': 'GOOGLE DEEPMIND', 'type': 'ORGANIZATION', 'description': 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.'}, 'relationship': {'description': 'Marc Lanctot is a researcher at Google DeepMind, involved in reinforcement learning research.', 'strength': 9}}\n",
      "{'subject': {'name': 'NANDO DE FREITAS', 'type': 'PERSON', 'description': 'Nando de Freitas is a prominent researcher at Google DeepMind, specializing in machine learning and artificial intelligence.'}, 'object': {'name': 'GOOGLE DEEPMIND', 'type': 'ORGANIZATION', 'description': 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.'}, 'relationship': {'description': 'Nando de Freitas is a prominent researcher at Google DeepMind, specializing in machine learning.', 'strength': 9}}\n",
      "{'subject': {'name': 'DUELING NETWORK ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network Architecture is a neural network design that separates the representation of state values and action advantages for improved reinforcement learning.'}, 'object': {'name': 'GOOGLE DEEPMIND', 'type': 'ORGANIZATION', 'description': 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.'}, 'relationship': {'description': 'The Dueling Network Architecture was developed by researchers at Google DeepMind to enhance reinforcement learning.', 'strength': 8}}\n",
      "{'subject': {'name': 'DUELING NETWORK ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network Architecture is a neural network design that separates the representation of state values and action advantages for improved reinforcement learning.'}, 'object': {'name': 'ATARI 2600', 'type': 'GAME', 'description': 'Atari 2600 is a classic video game console used as a benchmark for testing reinforcement learning algorithms.'}, 'relationship': {'description': 'The Dueling Network Architecture is tested and evaluated using the Atari 2600 as a benchmark for reinforcement learning performance.', 'strength': 7}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The dueling network is a deep learning architecture that separates the estimation of state value and advantage functions, improving learning efficiency in reinforcement learning tasks.'}, 'object': {'name': 'DEEP Q-NETWORKS', 'type': 'ALGORITHM', 'description': 'Deep Q-Networks (DQN) is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.'}, 'relationship': {'description': 'The dueling network is an improvement over the traditional Deep Q-Networks, enhancing the learning process by separating value and advantage functions.', 'strength': 8}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The dueling network is a deep learning architecture that separates the estimation of state value and advantage functions, improving learning efficiency in reinforcement learning tasks.'}, 'object': {'name': 'SALIENT MAPS', 'type': 'TECHNOLOGY', 'description': 'Saliency maps are visual representations that highlight important features in input data, used to understand the focus of neural networks during decision-making.'}, 'relationship': {'description': \"Saliency maps are generated from the dueling network's value and advantage streams, providing insights into the network's focus during decision-making.\", 'strength': 7}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The dueling network is a deep learning architecture that separates the estimation of state value and advantage functions, improving learning efficiency in reinforcement learning tasks.'}, 'object': {'name': 'ATARI 2600', 'type': 'GAME', 'description': 'Atari 2600 is a classic video game console that serves as a testbed for reinforcement learning algorithms, where agents learn to play various games.'}, 'relationship': {'description': 'The dueling network architecture is evaluated on the Atari 2600 testbed, demonstrating its effectiveness in playing various games.', 'strength': 9}}\n",
      "{'subject': {'name': 'JACOBIANS', 'type': 'METHODOLOGY', 'description': 'Jacobian matrices are used in the computation of gradients, which help in understanding how changes in input affect the output of a neural network.'}, 'object': {'name': 'SALIENT MAPS', 'type': 'TECHNOLOGY', 'description': 'Saliency maps are visual representations that highlight important features in input data, used to understand the focus of neural networks during decision-making.'}, 'relationship': {'description': \"Jacobian computations are used to create saliency maps, which visualize the importance of different inputs in the network's decision-making process.\", 'strength': 6}}\n",
      "{'subject': {'name': 'DEEP Q-NETWORKS', 'type': 'ALGORITHM', 'description': 'Deep Q-Networks (DQN) is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.'}, 'object': {'name': 'ATARI 2600', 'type': 'GAME', 'description': 'Atari 2600 is a classic video game console that serves as a testbed for reinforcement learning algorithms, where agents learn to play various games.'}, 'relationship': {'description': 'Deep Q-Networks are applied to the Atari 2600 games, where they learn to play by observing game states and scores.', 'strength': 8}}\n",
      "{'subject': {'name': 'DEEP Q-NETWORK', 'type': 'TECHNOLOGY', 'description': 'A deep Q-network is a neural network used to approximate the Q-function in reinforcement learning, allowing for the estimation of state-action values.'}, 'object': {'name': 'REINFORCEMENT LEARNING', 'type': 'METHODOLOGY', 'description': 'Reinforcement learning is a type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize cumulative reward.'}, 'relationship': {'description': 'Deep Q-networks are a specific application of reinforcement learning techniques to approximate the Q-function.', 'strength': 8}}\n",
      "{'subject': {'name': 'ADVANTAGE FUNCTION', 'type': 'ALGORITHM', 'description': 'The advantage function measures the relative value of taking a specific action in a given state compared to the average value of all actions in that state.'}, 'object': {'name': 'STATE-ACTION VALUE FUNCTION', 'type': 'ALGORITHM', 'description': 'The state-action value function, or Q-function, estimates the expected return of taking a specific action in a given state under a particular policy.'}, 'relationship': {'description': 'The advantage function is derived from the state-action value function, providing a measure of the relative importance of actions.', 'strength': 7}}\n",
      "{'subject': {'name': 'BELLMAN EQUATION', 'type': 'ALGORITHM', 'description': 'The Bellman equation is a fundamental recursive equation in dynamic programming and reinforcement learning that relates the value of a state to the values of its successor states.'}, 'object': {'name': 'STATE-ACTION VALUE FUNCTION', 'type': 'ALGORITHM', 'description': 'The state-action value function, or Q-function, estimates the expected return of taking a specific action in a given state under a particular policy.'}, 'relationship': {'description': 'The Bellman equation is used to define the relationship between the state-action value function and the values of subsequent states.', 'strength': 9}}\n",
      "{'subject': {'name': 'POLICY GRADIENTS', 'type': 'METHODOLOGY', 'description': 'Policy gradients are a class of algorithms in reinforcement learning that optimize the policy directly by adjusting the parameters in the direction of the gradient of expected reward.'}, 'object': {'name': 'ADVANTAGE FUNCTION', 'type': 'ALGORITHM', 'description': 'The advantage function measures the relative value of taking a specific action in a given state compared to the average value of all actions in that state.'}, 'relationship': {'description': 'Policy gradients often utilize the advantage function to reduce variance in the estimation of policy updates.', 'strength': 6}}\n",
      "{'subject': {'name': 'DQN', 'type': 'TECHNOLOGY', 'description': 'DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.'}, 'object': {'name': 'DDQN', 'type': 'TECHNOLOGY', 'description': 'DDQN, or Double Deep Q-Network, is an improved version of DQN that mitigates overestimation bias by using two separate networks for action selection and evaluation.'}, 'relationship': {'description': 'DDQN is an improved version of DQN that addresses its limitations.', 'strength': 9}}\n",
      "{'subject': {'name': 'DQN', 'type': 'TECHNOLOGY', 'description': 'DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.'}, 'object': {'name': 'EXPERIENCE REPLAY', 'type': 'METHODOLOGY', 'description': 'Experience replay is a technique used in reinforcement learning where past experiences are stored and reused to improve learning efficiency and reduce variance.'}, 'relationship': {'description': 'Experience replay is a key component used in DQN to enhance learning efficiency.', 'strength': 8}}\n",
      "{'subject': {'name': 'DDQN', 'type': 'TECHNOLOGY', 'description': 'DDQN, or Double Deep Q-Network, is an improved version of DQN that mitigates overestimation bias by using two separate networks for action selection and evaluation.'}, 'object': {'name': 'EXPERIENCE REPLAY', 'type': 'METHODOLOGY', 'description': 'Experience replay is a technique used in reinforcement learning where past experiences are stored and reused to improve learning efficiency and reduce variance.'}, 'relationship': {'description': 'DDQN also utilizes experience replay to improve its learning process.', 'strength': 8}}\n",
      "{'subject': {'name': 'EXPERIENCE REPLAY', 'type': 'METHODOLOGY', 'description': 'Experience replay is a technique used in reinforcement learning where past experiences are stored and reused to improve learning efficiency and reduce variance.'}, 'object': {'name': 'PRIORITIZED REPLAY', 'type': 'METHODOLOGY', 'description': 'Prioritized replay is an enhancement of experience replay that increases the probability of sampling experiences that are expected to provide more learning progress.'}, 'relationship': {'description': 'Prioritized replay builds upon the concept of experience replay to enhance learning.', 'strength': 7}}\n",
      "{'subject': {'name': 'DUELING NETWORK ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'The dueling network architecture is a design for Q-networks that separates the estimation of state values and action advantages to improve learning efficiency.'}, 'object': {'name': 'DQN', 'type': 'TECHNOLOGY', 'description': 'DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.'}, 'relationship': {'description': 'The dueling network architecture is designed to improve the performance of DQN.', 'strength': 8}}\n",
      "{'subject': {'name': 'MNIH ET AL.', 'type': 'PERSON', 'description': 'Mnih et al. refers to a group of researchers who developed the original DQN algorithm and contributed significantly to the field of deep reinforcement learning.'}, 'object': {'name': 'DQN', 'type': 'TECHNOLOGY', 'description': 'DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.'}, 'relationship': {'description': 'Mnih et al. are the original developers of the DQN algorithm.', 'strength': 10}}\n",
      "{'subject': {'name': 'VAN HASSELT ET AL.', 'type': 'PERSON', 'description': 'Van Hasselt et al. refers to researchers who proposed the Double DQN algorithm to address issues with the original DQN.'}, 'object': {'name': 'DDQN', 'type': 'TECHNOLOGY', 'description': 'DDQN, or Double Deep Q-Network, is an improved version of DQN that mitigates overestimation bias by using two separate networks for action selection and evaluation.'}, 'relationship': {'description': 'Van Hasselt et al. proposed the DDQN algorithm as an enhancement to DQN.', 'strength': 10}}\n",
      "{'subject': {'name': 'SCHAUL ET AL.', 'type': 'PERSON', 'description': 'Schaul et al. refers to researchers who introduced prioritized experience replay, enhancing the efficiency of reinforcement learning.'}, 'object': {'name': 'PRIORITIZED REPLAY', 'type': 'METHODOLOGY', 'description': 'Prioritized replay is an enhancement of experience replay that increases the probability of sampling experiences that are expected to provide more learning progress.'}, 'relationship': {'description': 'Schaul et al. introduced the concept of prioritized replay to improve experience replay.', 'strength': 9}}\n",
      "{'subject': {'name': 'ATARI BENCHMARK SUITE', 'type': 'DOMAIN', 'description': 'The Atari benchmark suite is a collection of video games used to evaluate the performance of reinforcement learning algorithms.'}, 'object': {'name': 'DQN', 'type': 'TECHNOLOGY', 'description': 'DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.'}, 'relationship': {'description': 'The Atari benchmark suite is commonly used to evaluate the performance of DQN and other reinforcement learning algorithms.', 'strength': 8}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network architecture is a deep reinforcement learning model that separates the estimation of the value and advantage functions through two streams of fully connected layers.'}, 'object': {'name': 'Q-FUNCTION', 'type': 'TECHNOLOGY', 'description': 'The Q-function is a function used in reinforcement learning that estimates the expected utility of taking a given action in a given state.'}, 'relationship': {'description': 'The Dueling Network architecture outputs a Q-function that estimates the expected utility of actions.', 'strength': 8}}\n",
      "{'subject': {'name': 'DDQN', 'type': 'ALGORITHM', 'description': 'DDQN, or Double Deep Q-Network, is an algorithm that addresses the overestimation bias of Q-learning by using two separate networks to estimate the Q-values.'}, 'object': {'name': 'Q-FUNCTION', 'type': 'TECHNOLOGY', 'description': 'The Q-function is a function used in reinforcement learning that estimates the expected utility of taking a given action in a given state.'}, 'relationship': {'description': 'DDQN is an algorithm that can be used to train the Q-function in reinforcement learning.', 'strength': 7}}\n",
      "{'subject': {'name': 'SARSA', 'type': 'ALGORITHM', 'description': 'SARSA (State-Action-Reward-State-Action) is an on-policy reinforcement learning algorithm that updates the Q-values based on the action taken by the agent.'}, 'object': {'name': 'Q-FUNCTION', 'type': 'TECHNOLOGY', 'description': 'The Q-function is a function used in reinforcement learning that estimates the expected utility of taking a given action in a given state.'}, 'relationship': {'description': 'SARSA is another algorithm that updates the Q-function based on the actions taken by the agent.', 'strength': 7}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network architecture is a deep reinforcement learning model that separates the estimation of the value and advantage functions through two streams of fully connected layers.'}, 'object': {'name': 'DDQN', 'type': 'ALGORITHM', 'description': 'DDQN, or Double Deep Q-Network, is an algorithm that addresses the overestimation bias of Q-learning by using two separate networks to estimate the Q-values.'}, 'relationship': {'description': 'The Dueling Network architecture can be trained using the DDQN algorithm to improve its performance.', 'strength': 6}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network architecture is a deep reinforcement learning model that separates the estimation of the value and advantage functions through two streams of fully connected layers.'}, 'object': {'name': 'SARSA', 'type': 'ALGORITHM', 'description': 'SARSA (State-Action-Reward-State-Action) is an on-policy reinforcement learning algorithm that updates the Q-values based on the action taken by the agent.'}, 'relationship': {'description': 'The Dueling Network architecture can also be trained using the SARSA algorithm for reinforcement learning tasks.', 'strength': 6}}\n",
      "{'subject': {'name': 'EQUATION (9)', 'type': 'TECHNOLOGY', 'description': 'Equation (9) is a mathematical formulation used in the experiments to help with identifiability and to evaluate Q-values in reinforcement learning.'}, 'object': {'name': 'DUELING ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'The dueling architecture is a neural network design that separates the representation of state values and advantages to improve learning in reinforcement learning tasks.'}, 'relationship': {'description': \"Equation (9) is implemented as part of the dueling architecture, indicating its role in the network's functioning.\", 'strength': 7}}\n",
      "{'subject': {'name': 'DUELING ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'The dueling architecture is a neural network design that separates the representation of state values and advantages to improve learning in reinforcement learning tasks.'}, 'object': {'name': 'DEEP Q-NETWORK', 'type': 'ALGORITHM', 'description': 'The deep Q-network is a reinforcement learning algorithm that uses deep learning to approximate Q-values for decision making.'}, 'relationship': {'description': 'The dueling architecture shares the same input-output interface with standard Q-networks, allowing it to utilize deep Q-learning algorithms.', 'strength': 8}}\n",
      "{'subject': {'name': 'DUELING ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'The dueling architecture is a neural network design that separates the representation of state values and advantages to improve learning in reinforcement learning tasks.'}, 'object': {'name': 'ATARI GAME-PLAYING', 'type': 'GAME', 'description': 'Atari game-playing refers to the use of reinforcement learning algorithms to learn and play various Atari video games.'}, 'relationship': {'description': 'The dueling architecture is evaluated on its performance in learning policies for Atari game-playing tasks.', 'strength': 9}}\n",
      "{'subject': {'name': 'CORRIDOR ENVIRONMENT', 'type': 'ENVIRONMENT', 'description': 'The corridor environment is a simple setup used for evaluating reinforcement learning algorithms, consisting of connected corridors where an agent must navigate to achieve rewards.'}, 'object': {'name': 'DUELING ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'The dueling architecture is a neural network design that separates the representation of state values and advantages to improve learning in reinforcement learning tasks.'}, 'relationship': {'description': 'The corridor environment is used to measure the performance of the dueling architecture in a controlled setting.', 'strength': 8}}\n",
      "{'subject': {'name': 'DUELING NETWORK ARCHITECTURES', 'type': 'TECHNOLOGY', 'description': 'Dueling Network Architectures are a type of neural network architecture used in deep reinforcement learning that improves convergence speed by learning a general value shared across similar actions.'}, 'object': {'name': 'DEEP REINFORCEMENT LEARNING', 'type': 'METHODOLOGY', 'description': 'Deep Reinforcement Learning is a methodology that combines reinforcement learning with deep learning to enable agents to learn optimal behaviors in complex environments.'}, 'relationship': {'description': 'Dueling Network Architectures are utilized within the framework of Deep Reinforcement Learning to enhance performance.', 'strength': 8}}\n",
      "{'subject': {'name': 'DDQN ALGORITHM', 'type': 'ALGORITHM', 'description': 'The DDQN (Double Deep Q-Network) algorithm is an enhancement of the Q-learning algorithm that reduces overestimation bias in action value estimates.'}, 'object': {'name': 'DUELING NETWORK ARCHITECTURES', 'type': 'TECHNOLOGY', 'description': 'Dueling Network Architectures are a type of neural network architecture used in deep reinforcement learning that improves convergence speed by learning a general value shared across similar actions.'}, 'relationship': {'description': 'The DDQN algorithm is designed to work with Dueling Network Architectures to improve learning efficiency.', 'strength': 7}}\n",
      "{'subject': {'name': 'CORRIDOR ENVIRONMENT', 'type': 'ENVIRONMENT', 'description': 'The Corridor Environment is a simulated environment used in reinforcement learning experiments where an agent navigates through a corridor to reach reward states.'}, 'object': {'name': 'ATARI GAMES', 'type': 'GAME', 'description': 'Atari Games are a collection of video games used as benchmarks in reinforcement learning research, known for their diverse gameplay and high-dimensional observations.'}, 'relationship': {'description': 'The Corridor Environment is a type of environment used to evaluate algorithms that can also be applied to various Atari Games.', 'strength': 5}}\n",
      "{'subject': {'name': 'DEEP REINFORCEMENT LEARNING', 'type': 'METHODOLOGY', 'description': 'Deep Reinforcement Learning is a methodology that combines reinforcement learning with deep learning to enable agents to learn optimal behaviors in complex environments.'}, 'object': {'name': 'ATARI GAMES', 'type': 'GAME', 'description': 'Atari Games are a collection of video games used as benchmarks in reinforcement learning research, known for their diverse gameplay and high-dimensional observations.'}, 'relationship': {'description': 'Deep Reinforcement Learning methodologies are applied to learn optimal strategies in Atari Games.', 'strength': 9}}\n",
      "{'subject': {'name': 'DDQN', 'type': 'ALGORITHM', 'description': 'DDQN (Double Deep Q-Network) is an algorithm that addresses the overestimation bias of Q-learning by using two separate networks to estimate action values.'}, 'object': {'name': 'DUELING ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'Dueling architecture is a neural network design that separates the representation of state values and action advantages to improve learning efficiency in reinforcement learning.'}, 'relationship': {'description': 'DDQN utilizes the dueling architecture to enhance its performance in reinforcement learning tasks.', 'strength': 8}}\n",
      "{'subject': {'name': 'VAN HASSELT ET AL. (2015)', 'type': 'PERSON', 'description': 'Van Hasselt et al. (2015) is a research team known for their contributions to deep reinforcement learning, particularly in the development of the DDQN algorithm.'}, 'object': {'name': 'DDQN', 'type': 'ALGORITHM', 'description': 'DDQN (Double Deep Q-Network) is an algorithm that addresses the overestimation bias of Q-learning by using two separate networks to estimate action values.'}, 'relationship': {'description': 'Van Hasselt et al. (2015) developed the DDQN algorithm, contributing significantly to the field of deep reinforcement learning.', 'strength': 9}}\n",
      "{'subject': {'name': 'NATURE DQN', 'type': 'ALGORITHM', 'description': 'Nature DQN is a deep reinforcement learning algorithm introduced by Mnih et al. (2015) that combines deep learning with Q-learning to play Atari games.'}, 'object': {'name': 'VAN HASSELT ET AL. (2015)', 'type': 'PERSON', 'description': 'Van Hasselt et al. (2015) is a research team known for their contributions to deep reinforcement learning, particularly in the development of the DDQN algorithm.'}, 'relationship': {'description': 'Nature DQN serves as a baseline for comparison against the DDQN algorithm developed by Van Hasselt et al. (2015).', 'strength': 6}}\n",
      "{'subject': {'name': 'ALE', 'type': 'ENVIRONMENT', 'description': 'ALE (Arcade Learning Environment) is a framework for developing and evaluating reinforcement learning agents in a variety of Atari games.'}, 'object': {'name': 'DDQN', 'type': 'ALGORITHM', 'description': 'DDQN (Double Deep Q-Network) is an algorithm that addresses the overestimation bias of Q-learning by using two separate networks to estimate action values.'}, 'relationship': {'description': 'ALE provides the environment in which the DDQN algorithm is tested and evaluated.', 'strength': 7}}\n",
      "{'subject': {'name': 'DUEL CLIP', 'type': 'ALGORITHM', 'description': 'Duel Clip is an algorithm that performs better than Single Clip on 75.4% of the games and achieves human-level performance on 42 out of 57 Atari games.'}, 'object': {'name': 'SINGLE CLIP', 'type': 'ALGORITHM', 'description': 'Single Clip is an algorithm that is outperformed by Duel Clip in various metrics across Atari games.'}, 'relationship': {'description': 'Duel Clip outperforms Single Clip on 75.4% of the games.', 'strength': 8}}\n",
      "{'subject': {'name': 'DUEL CLIP', 'type': 'ALGORITHM', 'description': 'Duel Clip is an algorithm that performs better than Single Clip on 75.4% of the games and achieves human-level performance on 42 out of 57 Atari games.'}, 'object': {'name': 'SINGLE', 'type': 'ALGORITHM', 'description': 'Single is a baseline algorithm that Duel Clip outperforms on 80.7% of the games.'}, 'relationship': {'description': 'Duel Clip achieves higher scores compared to the Single baseline on 80.7% of the games.', 'strength': 8}}\n",
      "{'subject': {'name': 'SINGLE CLIP', 'type': 'ALGORITHM', 'description': 'Single Clip is an algorithm that is outperformed by Duel Clip in various metrics across Atari games.'}, 'object': {'name': 'SINGLE', 'type': 'ALGORITHM', 'description': 'Single is a baseline algorithm that Duel Clip outperforms on 80.7% of the games.'}, 'relationship': {'description': 'Single Clip is a variant of the Single algorithm, which is used as a baseline.', 'strength': 5}}\n",
      "{'subject': {'name': 'DUEL CLIP', 'type': 'ALGORITHM', 'description': 'Duel Clip is an algorithm that performs better than Single Clip on 75.4% of the games and achieves human-level performance on 42 out of 57 Atari games.'}, 'object': {'name': 'GRADIENT CLIPPING', 'type': 'METHODOLOGY', 'description': 'Gradient clipping is a technique incorporated in the new approaches to improve performance.'}, 'relationship': {'description': 'Duel Clip incorporates gradient clipping to achieve its performance improvements.', 'strength': 7}}\n",
      "{'subject': {'name': 'DUEL CLIP', 'type': 'ALGORITHM', 'description': 'Duel Clip is an algorithm that performs better than Single Clip on 75.4% of the games and achieves human-level performance on 42 out of 57 Atari games.'}, 'object': {'name': 'PRIORITIZED EXPERIENCE REPLAY', 'type': 'METHODOLOGY', 'description': 'Prioritized Experience Replay is a methodology that improves the performance of Atari games by prioritizing experience tuples for learning.'}, 'relationship': {'description': 'Duel Clip can be combined with Prioritized Experience Replay to further improve performance.', 'strength': 6}}\n",
      "{'subject': {'name': 'PRIORITIZED EXPERIENCE REPLAY', 'type': 'METHODOLOGY', 'description': 'Prioritized Experience Replay is a methodology that improves the performance of Atari games by prioritizing experience tuples for learning.'}, 'object': {'name': 'GRADIENT CLIPPING', 'type': 'METHODOLOGY', 'description': 'Gradient clipping is a technique incorporated in the new approaches to improve performance.'}, 'relationship': {'description': 'Both methodologies are used to enhance the performance of algorithms in Atari games.', 'strength': 4}}\n",
      "{'subject': {'name': 'DUELING ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'Dueling architecture is a neural network architecture used in deep reinforcement learning that separates the representation of state values and advantages to improve learning efficiency.'}, 'object': {'name': 'PRIORITIZED DDQN', 'type': 'ALGORITHM', 'description': 'Prioritized DDQN is an algorithm that enhances the standard Double Deep Q-Network by prioritizing the experience replay based on the TD-error, allowing the agent to learn more effectively from important transitions.'}, 'relationship': {'description': 'Dueling architecture is used in conjunction with the Prioritized DDQN algorithm to enhance learning performance in reinforcement learning tasks.', 'strength': 8}}\n",
      "{'subject': {'name': 'GRADIENT CLIPPING', 'type': 'METHODOLOGY', 'description': 'Gradient clipping is a technique used to prevent exploding gradients by capping the gradients during backpropagation to a specified threshold.'}, 'object': {'name': 'PRIORITIZED DDQN', 'type': 'ALGORITHM', 'description': 'Prioritized DDQN is an algorithm that enhances the standard Double Deep Q-Network by prioritizing the experience replay based on the TD-error, allowing the agent to learn more effectively from important transitions.'}, 'relationship': {'description': 'Gradient clipping is applied during the training of the Prioritized DDQN algorithm to stabilize learning by preventing large updates.', 'strength': 7}}\n",
      "{'subject': {'name': 'PRIORITIZED DDQN', 'type': 'ALGORITHM', 'description': 'Prioritized DDQN is an algorithm that enhances the standard Double Deep Q-Network by prioritizing the experience replay based on the TD-error, allowing the agent to learn more effectively from important transitions.'}, 'object': {'name': 'ATARI GAMES', 'type': 'DOMAIN', 'description': 'Atari games are a set of classic video games used as benchmarks in reinforcement learning research, providing a diverse set of environments for training and evaluating agents.'}, 'relationship': {'description': 'The Prioritized DDQN algorithm is evaluated on Atari games to measure its performance and improvements over previous algorithms.', 'strength': 9}}\n",
      "{'subject': {'name': 'DUELING ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'Dueling architecture is a neural network architecture used in deep reinforcement learning that separates the representation of state values and advantages to improve learning efficiency.'}, 'object': {'name': 'ENDURO', 'type': 'GAME', 'description': 'Enduro is an Atari game where players control a car in a racing environment, focusing on endurance and performance over time.'}, 'relationship': {'description': \"The Dueling architecture is applied to the Enduro game to improve the agent's performance in learning to navigate the racing environment.\", 'strength': 6}}\n",
      "{'subject': {'name': 'DUELING ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'Dueling architecture is a neural network design that separates the representation of state values and action advantages, improving the learning efficiency in reinforcement learning tasks.'}, 'object': {'name': 'DEEP Q-NETWORKS', 'type': 'TECHNOLOGY', 'description': 'Deep Q-Networks (DQN) are a type of deep learning model used in reinforcement learning that combines Q-learning with deep neural networks to approximate Q-values.'}, 'relationship': {'description': 'Dueling architecture is an improvement applied to deep Q-networks to enhance their performance in reinforcement learning tasks.', 'strength': 8}}\n",
      "{'subject': {'name': 'Q-LEARNING', 'type': 'METHODOLOGY', 'description': 'Q-learning is a reinforcement learning algorithm that seeks to learn the value of an action in a particular state, allowing an agent to learn how to optimally act in an environment.'}, 'object': {'name': 'DEEP Q-NETWORKS', 'type': 'TECHNOLOGY', 'description': 'Deep Q-Networks (DQN) are a type of deep learning model used in reinforcement learning that combines Q-learning with deep neural networks to approximate Q-values.'}, 'relationship': {'description': 'Q-learning serves as the foundational methodology that deep Q-networks utilize to learn optimal policies.', 'strength': 9}}\n",
      "{'subject': {'name': 'SEAQUEST', 'type': 'GAME', 'description': 'Seaquest is an Atari game used as a benchmark for testing reinforcement learning algorithms, where players control a submarine to rescue divers while avoiding enemy attacks.'}, 'object': {'name': 'ATARI DOMAIN', 'type': 'DOMAIN', 'description': 'The Atari domain refers to a set of video games developed by Atari, which are commonly used as environments for testing reinforcement learning algorithms.'}, 'relationship': {'description': 'Seaquest is a specific game within the Atari domain, used for evaluating reinforcement learning algorithms.', 'strength': 7}}\n",
      "{'subject': {'name': 'DUELING ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'Dueling architecture is a neural network design that separates the representation of state values and action advantages, improving the learning efficiency in reinforcement learning tasks.'}, 'object': {'name': 'SEAQUEST', 'type': 'GAME', 'description': 'Seaquest is an Atari game used as a benchmark for testing reinforcement learning algorithms, where players control a submarine to rescue divers while avoiding enemy attacks.'}, 'relationship': {'description': 'The dueling architecture has been tested and shown to improve performance in the game Seaquest.', 'strength': 6}}\n",
      "{'subject': {'name': 'ICLR', 'type': 'ORGANIZATION', 'description': 'ICLR (International Conference on Learning Representations) is a prominent conference in the field of machine learning and artificial intelligence, focusing on deep learning and representation learning.'}, 'object': {'name': 'DEEP LEARNING WORKSHOP', 'type': 'EVENT', 'description': 'The Deep Learning Workshop is an event held at ICML that focuses on advancements and research in deep learning techniques and applications.'}, 'relationship': {'description': 'The Deep Learning Workshop is held as part of the ICLR conference, focusing on deep learning research.', 'strength': 8}}\n",
      "{'subject': {'name': 'NATURE', 'type': 'ORGANIZATION', 'description': 'Nature is a leading international journal that publishes research across a wide range of scientific disciplines, including significant studies in artificial intelligence and machine learning.'}, 'object': {'name': 'DEEP REINFORCEMENT LEARNING', 'type': 'METHODOLOGY', 'description': 'Deep reinforcement learning is a methodology that combines reinforcement learning with deep learning, enabling agents to learn optimal behaviors in complex environments through trial and error.'}, 'relationship': {'description': 'Nature publishes significant research articles on deep reinforcement learning methodologies.', 'strength': 7}}\n",
      "{'subject': {'name': 'ARXIV', 'type': 'ORGANIZATION', 'description': 'arXiv is a repository of electronic preprints (known as e-prints) in various fields of science, including computer science, where researchers share their findings before formal peer review.'}, 'object': {'name': 'DEEP REINFORCEMENT LEARNING', 'type': 'METHODOLOGY', 'description': 'Deep reinforcement learning is a methodology that combines reinforcement learning with deep learning, enabling agents to learn optimal behaviors in complex environments through trial and error.'}, 'relationship': {'description': 'Many researchers publish their findings on deep reinforcement learning on arXiv before formal publication.', 'strength': 6}}\n",
      "{'subject': {'name': 'NIPS', 'type': 'EVENT', 'description': 'NIPS (NeurIPS) is the Conference on Neural Information Processing Systems, a premier conference in machine learning and computational neuroscience.'}, 'object': {'name': 'DEEP REINFORCEMENT LEARNING', 'type': 'METHODOLOGY', 'description': 'Deep reinforcement learning is a methodology that combines reinforcement learning with deep learning, enabling agents to learn optimal behaviors in complex environments through trial and error.'}, 'relationship': {'description': 'NIPS features numerous papers and discussions on deep reinforcement learning methodologies.', 'strength': 8}}\n"
     ]
    }
   ],
   "source": [
    "for triplet in pipeline.triplets:\n",
    "    print(triplet.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'zz' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mzz\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'zz' is not defined"
     ]
    }
   ],
   "source": [
    "zz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dialog_generation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
