{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Combined Triplet Extractor initialized!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from document_pipeline import DocumentPipeline\n",
    "\n",
    "\n",
    "config = json.load(open(\"config.json\"))\n",
    "pipeline = DocumentPipeline(config[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Document was split into 12 documents\n",
      "Entity types not found! Quering LLM to find it...\n",
      "Searching for following entities: ['person', 'organization', 'location', 'technology', 'methodology', 'algorithm', 'framework', 'domain', 'architecture', 'game']\n",
      "Found 10 entities and 9 relationships!\n",
      "Searching for following entities: ['person', 'organization', 'location', 'technology', 'methodology', 'algorithm', 'framework', 'domain', 'architecture', 'game']\n",
      "Found 6 entities and 5 relationships!\n",
      "Searching for following entities: ['person', 'organization', 'location', 'technology', 'methodology', 'algorithm', 'framework', 'domain', 'architecture', 'game']\n",
      "Found 7 entities and 6 relationships!\n",
      "Searching for following entities: ['person', 'organization', 'location', 'technology', 'methodology', 'algorithm', 'framework', 'domain', 'architecture', 'game']\n",
      "Found 6 entities and 5 relationships!\n",
      "Searching for following entities: ['person', 'organization', 'location', 'technology', 'methodology', 'algorithm', 'framework', 'domain', 'architecture', 'game']\n",
      "Found 4 entities and 5 relationships!\n",
      "Searching for following entities: ['person', 'organization', 'location', 'technology', 'methodology', 'algorithm', 'framework', 'domain', 'architecture', 'game']\n",
      "Found 0 entities and 0 relationships!\n",
      "Searching for following entities: ['person', 'organization', 'location', 'technology', 'methodology', 'algorithm', 'framework', 'domain', 'architecture', 'game']\n",
      "Found 5 entities and 4 relationships!\n",
      "Searching for following entities: ['person', 'organization', 'location', 'technology', 'methodology', 'algorithm', 'framework', 'domain', 'architecture', 'game']\n",
      "Found 6 entities and 4 relationships!\n",
      "Searching for following entities: ['person', 'organization', 'location', 'technology', 'methodology', 'algorithm', 'framework', 'domain', 'architecture', 'game']\n",
      "Found 6 entities and 8 relationships!\n",
      "Searching for following entities: ['person', 'organization', 'location', 'technology', 'methodology', 'algorithm', 'framework', 'domain', 'architecture', 'game']\n",
      "Found 5 entities and 4 relationships!\n",
      "Searching for following entities: ['person', 'organization', 'location', 'technology', 'methodology', 'algorithm', 'framework', 'domain', 'architecture', 'game']\n",
      "Found 6 entities and 4 relationships!\n",
      "Searching for following entities: ['person', 'organization', 'location', 'technology', 'methodology', 'algorithm', 'framework', 'domain', 'architecture', 'game']\n",
      "Found 7 entities and 6 relationships!\n",
      "Relationship subject=['MIT PRESS', 'ORGANIZATION'] object=['SUTTON, R. S.', 'PERSON'] relationship_description=\"MIT Press published the book 'Introduction to Reinforcement Learning' authored by Sutton and Barto.\" relationship_strength=8 invalid!\n",
      "Total number of triplets: 59\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<triplet_extraction.classes.Triplet at 0x21447bc33e0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bc3650>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bc36b0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bc3710>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bc3770>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bc37d0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bc0080>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bc2150>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bc22d0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447ce6990>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447ce72f0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447ce7350>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447ce73b0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447ce7410>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bf4e30>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bf5340>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bf53a0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bf5400>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bf5460>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bf54c0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bf7560>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bf75c0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bf4e60>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bf7620>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447bf76b0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c36990>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c360f0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c36a50>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c36ae0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c36b70>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c31790>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c31820>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c318b0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c31940>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c32660>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c326c0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c32840>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c32960>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c3dc10>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c3dca0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c3dd30>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c3ddc0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c3de50>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c3de80>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c3df10>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c3dfa0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c3f0e0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c3f170>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c3f200>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c3f290>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c254c0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c25550>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c255e0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c25670>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c1cb90>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c1c830>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c1cc50>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c1cce0>,\n",
       " <triplet_extraction.classes.Triplet at 0x21447c1cd40>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subject': {'name': 'ZIYU WANG', 'type': 'PERSON', 'description': 'Ziyu Wang is a researcher associated with Google DeepMind, contributing to advancements in deep reinforcement learning.'}, 'object': {'name': 'GOOGLE DEEPMIND', 'type': 'ORGANIZATION', 'description': 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.'}, 'relationship': {'description': 'Ziyu Wang is a researcher at Google DeepMind, contributing to their projects.', 'strength': 9}}\n",
      "{'subject': {'name': 'TOM SCHAUL', 'type': 'PERSON', 'description': 'Tom Schaul is a researcher at Google DeepMind, known for his work in reinforcement learning and neural network architectures.'}, 'object': {'name': 'GOOGLE DEEPMIND', 'type': 'ORGANIZATION', 'description': 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.'}, 'relationship': {'description': 'Tom Schaul is a researcher at Google DeepMind, contributing to their projects.', 'strength': 9}}\n",
      "{'subject': {'name': 'MATTEO HESSEL', 'type': 'PERSON', 'description': 'Matteo Hessel is a researcher at Google DeepMind, focusing on deep learning and reinforcement learning methodologies.'}, 'object': {'name': 'GOOGLE DEEPMIND', 'type': 'ORGANIZATION', 'description': 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.'}, 'relationship': {'description': 'Matteo Hessel is a researcher at Google DeepMind, contributing to their projects.', 'strength': 9}}\n",
      "{'subject': {'name': 'HADO VAN HASSELT', 'type': 'PERSON', 'description': 'Hado van Hasselt is a researcher at Google DeepMind, recognized for his contributions to reinforcement learning and deep learning.'}, 'object': {'name': 'GOOGLE DEEPMIND', 'type': 'ORGANIZATION', 'description': 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.'}, 'relationship': {'description': 'Hado van Hasselt is a researcher at Google DeepMind, contributing to their projects.', 'strength': 9}}\n",
      "{'subject': {'name': 'MARC LANCTOT', 'type': 'PERSON', 'description': 'Marc Lanctot is a researcher at Google DeepMind, involved in developing algorithms for reinforcement learning.'}, 'object': {'name': 'GOOGLE DEEPMIND', 'type': 'ORGANIZATION', 'description': 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.'}, 'relationship': {'description': 'Marc Lanctot is a researcher at Google DeepMind, contributing to their projects.', 'strength': 9}}\n",
      "{'subject': {'name': 'NANDO DE FREITAS', 'type': 'PERSON', 'description': 'Nando de Freitas is a prominent researcher at Google DeepMind, specializing in machine learning and reinforcement learning.'}, 'object': {'name': 'GOOGLE DEEPMIND', 'type': 'ORGANIZATION', 'description': 'Google DeepMind is a leading artificial intelligence research lab known for its work in deep learning and reinforcement learning.'}, 'relationship': {'description': 'Nando de Freitas is a researcher at Google DeepMind, contributing to their projects.', 'strength': 9}}\n",
      "{'subject': {'name': 'DUELING NETWORK ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network Architecture is a neural network design for reinforcement learning that separates the representation of state values and action advantages.'}, 'object': {'name': 'DEEP REINFORCEMENT LEARNING', 'type': 'METHODLOGY', 'description': 'Deep Reinforcement Learning is a method that combines reinforcement learning with deep learning techniques to solve complex decision-making problems.'}, 'relationship': {'description': 'The Dueling Network Architecture is a specific architecture used within the framework of Deep Reinforcement Learning.', 'strength': 8}}\n",
      "{'subject': {'name': 'DUELING NETWORK ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network Architecture is a neural network design for reinforcement learning that separates the representation of state values and action advantages.'}, 'object': {'name': 'ATARI 2600', 'type': 'GAME', 'description': 'Atari 2600 is a classic video game console used as a benchmark for testing reinforcement learning algorithms.'}, 'relationship': {'description': 'The Dueling Network Architecture has been tested and evaluated using the Atari 2600 as a benchmark for reinforcement learning performance.', 'strength': 7}}\n",
      "{'subject': {'name': 'DEEP REINFORCEMENT LEARNING', 'type': 'METHODLOGY', 'description': 'Deep Reinforcement Learning is a method that combines reinforcement learning with deep learning techniques to solve complex decision-making problems.'}, 'object': {'name': 'ATARI 2600', 'type': 'GAME', 'description': 'Atari 2600 is a classic video game console used as a benchmark for testing reinforcement learning algorithms.'}, 'relationship': {'description': 'Deep Reinforcement Learning methods have been applied to games like Atari 2600 to evaluate their effectiveness.', 'strength': 7}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The dueling network is a deep learning architecture that separates the estimation of state value and advantage functions, improving learning efficiency in reinforcement learning tasks.'}, 'object': {'name': 'DEEP Q-NETWORKS', 'type': 'ALGORITHM', 'description': 'Deep Q-Networks (DQN) is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.'}, 'relationship': {'description': 'The dueling network architecture improves upon the traditional Deep Q-Networks by separating value and advantage functions.', 'strength': 8}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The dueling network is a deep learning architecture that separates the estimation of state value and advantage functions, improving learning efficiency in reinforcement learning tasks.'}, 'object': {'name': 'ATARI 2600', 'type': 'GAME', 'description': 'Atari 2600 is a classic video game console that serves as a testbed for reinforcement learning algorithms, where agents learn to play various games.'}, 'relationship': {'description': 'The dueling network architecture is evaluated on the challenging Atari 2600 testbed to demonstrate its effectiveness in reinforcement learning.', 'strength': 7}}\n",
      "{'subject': {'name': 'SALIENT MAPS', 'type': 'TECHNOLOGY', 'description': 'Saliency maps are visual representations that highlight important features in input data, used to understand the focus of neural networks during decision-making.'}, 'object': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The dueling network is a deep learning architecture that separates the estimation of state value and advantage functions, improving learning efficiency in reinforcement learning tasks.'}, 'relationship': {'description': \"Saliency maps are generated to visualize the focus of the dueling network's value and advantage streams during decision-making.\", 'strength': 6}}\n",
      "{'subject': {'name': 'JACOBIANS', 'type': 'TECHNOLOGY', 'description': 'Jacobian matrices are used in calculus to represent the rate of change of a function with respect to its variables, applied here to analyze the trained value and advantage streams.'}, 'object': {'name': 'SALIENT MAPS', 'type': 'TECHNOLOGY', 'description': 'Saliency maps are visual representations that highlight important features in input data, used to understand the focus of neural networks during decision-making.'}, 'relationship': {'description': 'Jacobian matrices are computed to create saliency maps that illustrate the importance of different inputs in the dueling network.', 'strength': 5}}\n",
      "{'subject': {'name': 'POLICY EVALUATION', 'type': 'METHODOLOGY', 'description': 'Policy evaluation is a process in reinforcement learning to assess the performance of a policy by calculating the expected return from each state.'}, 'object': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The dueling network is a deep learning architecture that separates the estimation of state value and advantage functions, improving learning efficiency in reinforcement learning tasks.'}, 'relationship': {'description': 'The dueling network architecture enhances the process of policy evaluation by allowing for quicker identification of optimal actions.', 'strength': 7}}\n",
      "{'subject': {'name': 'DEEP Q-NETWORKS', 'type': 'TECHNOLOGY', 'description': 'Deep Q-Networks are a type of artificial intelligence model that combines Q-learning with deep learning to approximate the Q-function, allowing agents to make decisions in high-dimensional spaces.'}, 'object': {'name': 'Q-FUNCTION', 'type': 'ALGORITHM', 'description': 'The Q-function is a function that estimates the expected return of taking a specific action in a given state, used in reinforcement learning to guide decision-making.'}, 'relationship': {'description': 'Deep Q-Networks utilize the Q-function to make decisions based on the expected returns of actions.', 'strength': 9}}\n",
      "{'subject': {'name': 'DEEP Q-NETWORKS', 'type': 'TECHNOLOGY', 'description': 'Deep Q-Networks are a type of artificial intelligence model that combines Q-learning with deep learning to approximate the Q-function, allowing agents to make decisions in high-dimensional spaces.'}, 'object': {'name': 'BELLMAN EQUATION', 'type': 'ALGORITHM', 'description': 'The Bellman Equation is a fundamental recursive equation in dynamic programming and reinforcement learning that relates the value of a state to the values of its successor states.'}, 'relationship': {'description': 'Deep Q-Networks are based on the principles of the Bellman Equation to compute the optimal Q-values.', 'strength': 8}}\n",
      "{'subject': {'name': 'Q-FUNCTION', 'type': 'ALGORITHM', 'description': 'The Q-function is a function that estimates the expected return of taking a specific action in a given state, used in reinforcement learning to guide decision-making.'}, 'object': {'name': 'ADVANTAGE FUNCTION', 'type': 'ALGORITHM', 'description': 'The Advantage Function measures the relative value of taking a specific action compared to the average value of all actions in a given state, helping to reduce variance in policy gradient methods.'}, 'relationship': {'description': 'The Advantage Function is derived from the Q-function to provide a relative measure of action importance.', 'strength': 7}}\n",
      "{'subject': {'name': 'POLICY GRADIENTS', 'type': 'METHODOLOGY', 'description': 'Policy gradients are a class of algorithms in reinforcement learning that optimize the policy directly by adjusting the parameters in the direction of higher expected rewards.'}, 'object': {'name': 'ADVANTAGE FUNCTION', 'type': 'ALGORITHM', 'description': 'The Advantage Function measures the relative value of taking a specific action compared to the average value of all actions in a given state, helping to reduce variance in policy gradient methods.'}, 'relationship': {'description': 'Policy gradients often use the Advantage Function to reduce variance in the updates to the policy.', 'strength': 8}}\n",
      "{'subject': {'name': 'REINFORCEMENT LEARNING', 'type': 'DOMAIN', 'description': 'Reinforcement Learning is a machine learning paradigm where an agent learns to make decisions by interacting with an environment to maximize cumulative rewards.'}, 'object': {'name': 'DEEP Q-NETWORKS', 'type': 'TECHNOLOGY', 'description': 'Deep Q-Networks are a type of artificial intelligence model that combines Q-learning with deep learning to approximate the Q-function, allowing agents to make decisions in high-dimensional spaces.'}, 'relationship': {'description': 'Deep Q-Networks are a specific application of reinforcement learning techniques.', 'strength': 10}}\n",
      "{'subject': {'name': 'ATARI', 'type': 'GAME', 'description': 'Atari refers to a series of video games that are commonly used as benchmarks in reinforcement learning research, providing a challenging environment for training agents.'}, 'object': {'name': 'REINFORCEMENT LEARNING', 'type': 'DOMAIN', 'description': 'Reinforcement Learning is a machine learning paradigm where an agent learns to make decisions by interacting with an environment to maximize cumulative rewards.'}, 'relationship': {'description': 'Atari games are commonly used as environments for testing and developing reinforcement learning algorithms.', 'strength': 9}}\n",
      "{'subject': {'name': 'DQN', 'type': 'ALGORITHM', 'description': 'DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.'}, 'object': {'name': 'EXPERIENCE REPLAY', 'type': 'METHODOLOGY', 'description': 'Experience replay is a technique used in reinforcement learning where past experiences are stored and reused to improve learning efficiency and reduce variance.'}, 'relationship': {'description': 'DQN utilizes experience replay to improve data efficiency and reduce variance during training.', 'strength': 8}}\n",
      "{'subject': {'name': 'DDQN', 'type': 'ALGORITHM', 'description': 'DDQN, or Double Deep Q-Network, is an improvement over DQN that mitigates overestimation bias by using two separate networks for action selection and evaluation.'}, 'object': {'name': 'DQN', 'type': 'ALGORITHM', 'description': 'DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.'}, 'relationship': {'description': 'DDQN is an improved version of DQN that addresses its overestimation bias.', 'strength': 9}}\n",
      "{'subject': {'name': 'PRIORITIZED REPLAY', 'type': 'METHODOLOGY', 'description': 'Prioritized replay is an enhancement of experience replay that focuses on replaying experiences that are expected to provide more learning progress.'}, 'object': {'name': 'DDQN', 'type': 'ALGORITHM', 'description': 'DDQN, or Double Deep Q-Network, is an improvement over DQN that mitigates overestimation bias by using two separate networks for action selection and evaluation.'}, 'relationship': {'description': 'Prioritized replay is used in conjunction with DDQN to enhance learning speed and policy quality.', 'strength': 7}}\n",
      "{'subject': {'name': 'DUELING NETWORK ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'Dueling Network Architecture is a neural network design that separates the estimation of state values and action advantages to improve learning efficiency in reinforcement learning.'}, 'object': {'name': 'DQN', 'type': 'ALGORITHM', 'description': 'DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.'}, 'relationship': {'description': 'The dueling network architecture is designed to work with DQN to improve its performance by separating value and advantage estimations.', 'strength': 8}}\n",
      "{'subject': {'name': 'ATARI BENCHMARK SUITE', 'type': 'DOMAIN', 'description': 'The Atari Benchmark Suite is a collection of Atari games used as a standard testing ground for evaluating reinforcement learning algorithms.'}, 'object': {'name': 'DQN', 'type': 'ALGORITHM', 'description': 'DQN, or Deep Q-Network, is a reinforcement learning algorithm that combines Q-learning with deep neural networks to approximate the Q-value function.'}, 'relationship': {'description': 'DQN is evaluated using the Atari Benchmark Suite to measure its performance across various games.', 'strength': 6}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network is a deep reinforcement learning architecture that separates the estimation of state value and action advantage functions.'}, 'object': {'name': 'Q-FUNCTION', 'type': 'TECHNOLOGY', 'description': 'The Q-function is a function used in reinforcement learning to estimate the expected utility of taking a given action in a given state.'}, 'relationship': {'description': 'The Dueling Network architecture outputs a Q-function that estimates the expected utility of actions.', 'strength': 8}}\n",
      "{'subject': {'name': 'DDQN', 'type': 'ALGORITHM', 'description': 'DDQN stands for Double Deep Q-Network, an algorithm that addresses the overestimation bias of Q-learning by using two networks.'}, 'object': {'name': 'Q-FUNCTION', 'type': 'TECHNOLOGY', 'description': 'The Q-function is a function used in reinforcement learning to estimate the expected utility of taking a given action in a given state.'}, 'relationship': {'description': 'DDQN is an algorithm that can be used to train the Q-function in reinforcement learning.', 'strength': 7}}\n",
      "{'subject': {'name': 'SARSA', 'type': 'ALGORITHM', 'description': 'SARSA is an on-policy reinforcement learning algorithm that updates the action-value function based on the action taken by the agent.'}, 'object': {'name': 'Q-FUNCTION', 'type': 'TECHNOLOGY', 'description': 'The Q-function is a function used in reinforcement learning to estimate the expected utility of taking a given action in a given state.'}, 'relationship': {'description': \"SARSA is another algorithm that utilizes the Q-function to update action values based on the agent's actions.\", 'strength': 7}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network is a deep reinforcement learning architecture that separates the estimation of state value and action advantage functions.'}, 'object': {'name': 'DDQN', 'type': 'ALGORITHM', 'description': 'DDQN stands for Double Deep Q-Network, an algorithm that addresses the overestimation bias of Q-learning by using two networks.'}, 'relationship': {'description': 'The Dueling Network can be trained using the DDQN algorithm to improve its performance.', 'strength': 6}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network is a deep reinforcement learning architecture that separates the estimation of state value and action advantage functions.'}, 'object': {'name': 'SARSA', 'type': 'ALGORITHM', 'description': 'SARSA is an on-policy reinforcement learning algorithm that updates the action-value function based on the action taken by the agent.'}, 'relationship': {'description': 'The Dueling Network can also be trained using the SARSA algorithm for reinforcement learning tasks.', 'strength': 6}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network is a deep reinforcement learning architecture that splits into two streams to learn a general value shared across similar actions, leading to faster convergence.'}, 'object': {'name': 'Q-NETWORK', 'type': 'ARCHITECTURE', 'description': 'The Q-Network is a traditional reinforcement learning architecture that evaluates the value of actions in a given state, used as a baseline for comparison with the Dueling Network.'}, 'relationship': {'description': 'The Dueling Network is compared against the traditional Q-Network to demonstrate its superior performance in reinforcement learning tasks.', 'strength': 8}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network is a deep reinforcement learning architecture that splits into two streams to learn a general value shared across similar actions, leading to faster convergence.'}, 'object': {'name': 'ATARI GAMES', 'type': 'GAME', 'description': 'A collection of 57 diverse games used in the Arcade Learning Environment for evaluating reinforcement learning algorithms.'}, 'relationship': {'description': 'The Dueling Network is evaluated on the Arcade Learning Environment, which consists of various Atari games.', 'strength': 7}}\n",
      "{'subject': {'name': 'DDQN', 'type': 'ALGORITHM', 'description': 'The Double DQN algorithm is an enhancement of the Q-learning algorithm that reduces overestimation bias by using two networks.'}, 'object': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network is a deep reinforcement learning architecture that splits into two streams to learn a general value shared across similar actions, leading to faster convergence.'}, 'relationship': {'description': 'The DDQN algorithm is used to train the Dueling Network, enhancing its performance in learning tasks.', 'strength': 9}}\n",
      "{'subject': {'name': 'ARCade LEARNING ENVIRONMENT', 'type': 'DOMAIN', 'description': 'A framework for evaluating reinforcement learning algorithms using a variety of Atari games.'}, 'object': {'name': 'ATARI GAMES', 'type': 'GAME', 'description': 'A collection of 57 diverse games used in the Arcade Learning Environment for evaluating reinforcement learning algorithms.'}, 'relationship': {'description': 'The Arcade Learning Environment is specifically designed to evaluate algorithms on a set of Atari games.', 'strength': 10}}\n",
      "{'subject': {'name': 'VAN HASSELT ET AL.', 'type': 'PERSON', 'description': 'Van Hasselt et al. (2015) proposed a single-stream network architecture for deep reinforcement learning.'}, 'object': {'name': 'SINGLE CLIP', 'type': 'ARCHITECTURE', 'description': 'Single Clip is a re-trained model that uses a single stream network architecture for comparison against the Dueling Network.'}, 'relationship': {'description': 'Single Clip is based on the architecture proposed by Van Hasselt et al. (2015).', 'strength': 8}}\n",
      "{'subject': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network architecture improves performance in deep reinforcement learning by separating the representation of state value and advantage.'}, 'object': {'name': 'SINGLE CLIP', 'type': 'ARCHITECTURE', 'description': 'Single Clip is a re-trained model that uses a single stream network architecture for comparison against the Dueling Network.'}, 'relationship': {'description': 'Single Clip is compared against the Dueling Network architecture to evaluate performance.', 'strength': 7}}\n",
      "{'subject': {'name': 'DEEP Q-NETWORK', 'type': 'ARCHITECTURE', 'description': 'The Deep Q-Network (DQN) is a model proposed by Mnih et al. (2015) that combines Q-learning with deep neural networks.'}, 'object': {'name': 'DUELING NETWORK', 'type': 'ARCHITECTURE', 'description': 'The Dueling Network architecture improves performance in deep reinforcement learning by separating the representation of state value and advantage.'}, 'relationship': {'description': 'The Dueling Network is an improvement over the Deep Q-Network architecture.', 'strength': 9}}\n",
      "{'subject': {'name': 'GRADIENT CLIPPING', 'type': 'METHOD', 'description': 'Gradient clipping is a technique used to prevent exploding gradients by capping the gradients during training.'}, 'object': {'name': 'REINFORCEMENT LEARNING', 'type': 'METHOD', 'description': 'Reinforcement Learning (RL) is a type of machine learning where agents learn to make decisions by receiving rewards or penalties.'}, 'relationship': {'description': 'Gradient clipping is a technique commonly used in reinforcement learning to stabilize training.', 'strength': 6}}\n",
      "{'subject': {'name': 'DUEL CLIP', 'type': 'ALGORITHM', 'description': 'Duel Clip is an algorithm that outperforms Single Clip on a majority of Atari games, achieving human-level performance in many cases.'}, 'object': {'name': 'SINGLE CLIP', 'type': 'ALGORITHM', 'description': 'Single Clip is an algorithm that performs well but is outperformed by Duel Clip in various scenarios.'}, 'relationship': {'description': 'Duel Clip outperforms Single Clip on a majority of Atari games, indicating a competitive relationship.', 'strength': 8}}\n",
      "{'subject': {'name': 'DUEL CLIP', 'type': 'ALGORITHM', 'description': 'Duel Clip is an algorithm that outperforms Single Clip on a majority of Atari games, achieving human-level performance in many cases.'}, 'object': {'name': 'GRADIENT CLIPPING', 'type': 'METHODOLOGY', 'description': 'Gradient clipping is a technique used to prevent exploding gradients during training, incorporated in the new approaches to improve performance.'}, 'relationship': {'description': 'Duel Clip incorporates gradient clipping to enhance its performance.', 'strength': 7}}\n",
      "{'subject': {'name': 'SINGLE CLIP', 'type': 'ALGORITHM', 'description': 'Single Clip is an algorithm that performs well but is outperformed by Duel Clip in various scenarios.'}, 'object': {'name': 'GRADIENT CLIPPING', 'type': 'METHODOLOGY', 'description': 'Gradient clipping is a technique used to prevent exploding gradients during training, incorporated in the new approaches to improve performance.'}, 'relationship': {'description': \"Single Clip's performance is also improved by the use of gradient clipping.\", 'strength': 6}}\n",
      "{'subject': {'name': 'DUEL CLIP', 'type': 'ALGORITHM', 'description': 'Duel Clip is an algorithm that outperforms Single Clip on a majority of Atari games, achieving human-level performance in many cases.'}, 'object': {'name': 'PRIORITIZED EXPERIENCE REPLAY', 'type': 'METHODOLOGY', 'description': 'Prioritized Experience Replay is a method that improves the performance of reinforcement learning algorithms by prioritizing important experiences.'}, 'relationship': {'description': 'Duel Clip can be combined with prioritized experience replay to further enhance its performance.', 'strength': 7}}\n",
      "{'subject': {'name': 'NATURE DQN', 'type': 'ALGORITHM', 'description': 'Nature DQN is a reinforcement learning algorithm that serves as a baseline for comparison with other algorithms like Duel Clip and Single Clip.'}, 'object': {'name': 'SINGLE CLIP', 'type': 'ALGORITHM', 'description': 'Single Clip is an algorithm that performs well but is outperformed by Duel Clip in various scenarios.'}, 'relationship': {'description': 'Nature DQN serves as a baseline for comparing the performance of Single Clip.', 'strength': 5}}\n",
      "{'subject': {'name': 'ATARI GAMES', 'type': 'DOMAIN', 'description': 'Atari games are a set of video games used as benchmarks for evaluating the performance of reinforcement learning algorithms.'}, 'object': {'name': 'DUEL CLIP', 'type': 'ALGORITHM', 'description': 'Duel Clip is an algorithm that outperforms Single Clip on a majority of Atari games, achieving human-level performance in many cases.'}, 'relationship': {'description': 'Duel Clip is evaluated based on its performance in Atari games.', 'strength': 9}}\n",
      "{'subject': {'name': 'ATARI GAMES', 'type': 'DOMAIN', 'description': 'Atari games are a set of video games used as benchmarks for evaluating the performance of reinforcement learning algorithms.'}, 'object': {'name': 'SINGLE CLIP', 'type': 'ALGORITHM', 'description': 'Single Clip is an algorithm that performs well but is outperformed by Duel Clip in various scenarios.'}, 'relationship': {'description': 'Single Clip is also evaluated based on its performance in Atari games.', 'strength': 9}}\n",
      "{'subject': {'name': 'ATARI GAMES', 'type': 'DOMAIN', 'description': 'Atari games are a set of video games used as benchmarks for evaluating the performance of reinforcement learning algorithms.'}, 'object': {'name': 'NATURE DQN', 'type': 'ALGORITHM', 'description': 'Nature DQN is a reinforcement learning algorithm that serves as a baseline for comparison with other algorithms like Duel Clip and Single Clip.'}, 'relationship': {'description': 'Nature DQN is evaluated in the context of Atari games, serving as a benchmark.', 'strength': 9}}\n",
      "{'subject': {'name': 'DUELING ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'Dueling architecture is a neural network architecture used in deep reinforcement learning that separates the representation of state values and advantages to improve learning efficiency.'}, 'object': {'name': 'PRIORITIZED DDQN', 'type': 'ALGORITHM', 'description': 'Prioritized DDQN is an algorithm that enhances the standard Double Deep Q-Network by prioritizing the experience replay based on the TD-error, allowing the agent to learn more effectively from important transitions.'}, 'relationship': {'description': 'Dueling architecture is used as a component in the prioritized DDQN algorithm to improve learning performance.', 'strength': 8}}\n",
      "{'subject': {'name': 'GRADIENT CLIPPING', 'type': 'METHODOLOGY', 'description': 'Gradient clipping is a technique used to prevent exploding gradients by capping the gradients during backpropagation to a specified threshold.'}, 'object': {'name': 'PRIORITIZED DDQN', 'type': 'ALGORITHM', 'description': 'Prioritized DDQN is an algorithm that enhances the standard Double Deep Q-Network by prioritizing the experience replay based on the TD-error, allowing the agent to learn more effectively from important transitions.'}, 'relationship': {'description': 'Gradient clipping is applied in the prioritized DDQN algorithm to stabilize training by preventing large updates.', 'strength': 7}}\n",
      "{'subject': {'name': 'PRIORITIZED DDQN', 'type': 'ALGORITHM', 'description': 'Prioritized DDQN is an algorithm that enhances the standard Double Deep Q-Network by prioritizing the experience replay based on the TD-error, allowing the agent to learn more effectively from important transitions.'}, 'object': {'name': 'ATARI GAMES', 'type': 'DOMAIN', 'description': 'Atari games are a set of video games used as benchmarks in reinforcement learning research, providing a diverse set of environments for evaluating learning algorithms.'}, 'relationship': {'description': 'The prioritized DDQN algorithm is evaluated on Atari games to measure its performance against human benchmarks.', 'strength': 9}}\n",
      "{'subject': {'name': 'DUELING ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'Dueling architecture is a neural network architecture used in deep reinforcement learning that separates the representation of state values and advantages to improve learning efficiency.'}, 'object': {'name': 'ENDURO', 'type': 'GAME', 'description': 'Enduro is an Atari game where players control a car and must race against other cars while managing fuel and avoiding collisions.'}, 'relationship': {'description': 'The dueling architecture is applied to the Enduro game to enhance the learning process in reinforcement learning tasks.', 'strength': 6}}\n",
      "{'subject': {'name': 'DUELING ARCHITECTURE', 'type': 'ARCHITECTURE', 'description': 'Dueling architecture is a neural network design that separates the representation of state values and action advantages, improving the learning efficiency in reinforcement learning tasks.'}, 'object': {'name': 'DEEP Q-NETWORKS', 'type': 'ALGORITHM', 'description': 'Deep Q-Networks (DQN) combine Q-learning with deep neural networks to approximate the Q-value function, enabling the handling of high-dimensional state spaces.'}, 'relationship': {'description': 'Dueling architecture is an improvement over traditional deep Q-networks, enhancing their performance in reinforcement learning tasks.', 'strength': 8}}\n",
      "{'subject': {'name': 'DEEP Q-NETWORKS', 'type': 'ALGORITHM', 'description': 'Deep Q-Networks (DQN) combine Q-learning with deep neural networks to approximate the Q-value function, enabling the handling of high-dimensional state spaces.'}, 'object': {'name': 'Q-LEARNING', 'type': 'ALGORITHM', 'description': 'Q-learning is a reinforcement learning algorithm that aims to learn the value of an action in a particular state, allowing an agent to make decisions that maximize its expected reward.'}, 'relationship': {'description': 'Deep Q-networks utilize Q-learning as their underlying algorithm to learn optimal policies in complex environments.', 'strength': 9}}\n",
      "{'subject': {'name': 'SEAQUEST', 'type': 'GAME', 'description': 'Seaquest is an Atari game used as a benchmark for testing reinforcement learning algorithms, where players control a submarine to rescue divers while avoiding enemy attacks.'}, 'object': {'name': 'DEEP REINFORCEMENT LEARNING', 'type': 'METHODLOGY', 'description': 'Deep Reinforcement Learning is a combination of reinforcement learning and deep learning, where deep neural networks are used to approximate the value functions or policies.'}, 'relationship': {'description': 'Seaquest is a game used to evaluate deep reinforcement learning methodologies, showcasing their effectiveness in real-time decision-making.', 'strength': 7}}\n",
      "{'subject': {'name': 'DEEP REINFORCEMENT LEARNING', 'type': 'METHODLOGY', 'description': 'Deep Reinforcement Learning is a combination of reinforcement learning and deep learning, where deep neural networks are used to approximate the value functions or policies.'}, 'object': {'name': 'ATARI', 'type': 'DOMAIN', 'description': 'Atari refers to a series of classic video games that serve as a popular benchmark for evaluating reinforcement learning algorithms.'}, 'relationship': {'description': 'Deep reinforcement learning is often tested in the Atari domain, which provides a variety of games for benchmarking.', 'strength': 6}}\n",
      "{'subject': {'name': 'ICLR', 'type': 'ORGANIZATION', 'description': 'ICLR (International Conference on Learning Representations) is a conference focused on deep learning and representation learning.'}, 'object': {'name': 'NATURE', 'type': 'ORGANIZATION', 'description': 'Nature is a prominent scientific journal that publishes research across a wide range of scientific fields.'}, 'relationship': {'description': 'ICLR publishes research that is often featured in Nature, highlighting significant advancements in deep learning.', 'strength': 7}}\n",
      "{'subject': {'name': 'DEEP REINFORCEMENT LEARNING', 'type': 'METHOD', 'description': 'Deep reinforcement learning is a method that combines reinforcement learning with deep learning to enable agents to learn optimal behaviors in complex environments.'}, 'object': {'name': 'GO', 'type': 'GAME', 'description': 'Go is an ancient board game that is known for its deep strategic elements and has been a benchmark for artificial intelligence research.'}, 'relationship': {'description': 'Deep reinforcement learning has been applied to master the game of Go, demonstrating its effectiveness in complex decision-making tasks.', 'strength': 9}}\n",
      "{'subject': {'name': 'NATURE', 'type': 'ORGANIZATION', 'description': 'Nature is a prominent scientific journal that publishes research across a wide range of scientific fields.'}, 'object': {'name': 'DEEP REINFORCEMENT LEARNING', 'type': 'METHOD', 'description': 'Deep reinforcement learning is a method that combines reinforcement learning with deep learning to enable agents to learn optimal behaviors in complex environments.'}, 'relationship': {'description': 'Nature publishes articles on deep reinforcement learning, showcasing its impact on various scientific fields.', 'strength': 8}}\n",
      "{'subject': {'name': 'ARXIV', 'type': 'ORGANIZATION', 'description': 'arXiv is a repository of electronic preprints (known as e-prints) in various fields of science, including computer science and mathematics.'}, 'object': {'name': 'ICLR', 'type': 'ORGANIZATION', 'description': 'ICLR (International Conference on Learning Representations) is a conference focused on deep learning and representation learning.'}, 'relationship': {'description': 'ICLR papers are often submitted to arXiv for public access prior to the conference.', 'strength': 6}}\n",
      "{'subject': {'name': 'NIPS', 'type': 'ORGANIZATION', 'description': 'NIPS (Neural Information Processing Systems) is a conference that focuses on machine learning and computational neuroscience.'}, 'object': {'name': 'DEEP REINFORCEMENT LEARNING', 'type': 'METHOD', 'description': 'Deep reinforcement learning is a method that combines reinforcement learning with deep learning to enable agents to learn optimal behaviors in complex environments.'}, 'relationship': {'description': 'NIPS features research on deep reinforcement learning, contributing to advancements in the field.', 'strength': 7}}\n"
     ]
    }
   ],
   "source": [
    "for triplet in pipeline.triplets:\n",
    "    print(triplet.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dialog_generation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
